{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook is to get files from AWS S3 bucket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# importing a library that simplifes interactions with AWS\n",
    "\n",
    "!pip install boto3 --quiet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import requests as re\n",
    "import pandas as pd\n",
    "from boto3.session import Session\n",
    "\n",
    "df = pd.read_csv('manually_scrapped.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# creating a session and connecting to our s3 bucket. you have to manually enter the \n",
    "# access keys - or at least i couldn't get them from .env\n",
    "\n",
    "ACCESS_KEY = 'your-access-key'\n",
    "SECRET_ACCESS_KEY = 'your-secret-access-key'\n",
    "\n",
    "session = Session(aws_access_key_id=ACCESS_KEY, \n",
    "                  aws_secret_access_key=SECRET_ACCESS_KEY)\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('hrf-asylum-cases')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# getting the filenames of the pdfs in the s3 hrf-asylum-cases bucket\n",
    "# these can be used in the make_fields function along with the files to\n",
    "# repopulate the ds_cases table.\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for s3_file in your_bucket.objects.all():\n",
    "    filenames.append(s3_file.key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# reloading the cases into the ds_cases table using the endpoint setup\n",
    "# through elasticbeanstalk\n",
    "\n",
    "\n",
    "API_URL = 'http://labs37-hrf-asylum-b-dev.us-east-1.elasticbeanstalk.com/pdf-ocr'        # your endpoint will go here\n",
    "\n",
    "for file in filenames:\n",
    "    file = file.strip('.pdf')\n",
    "    re.get(f'{API_URL}/{file}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# getting the files stored in the bucket. note they currently download to\n",
    "# the notebooks folder. change in open(). these files are needed\n",
    "# to check and calibrate the accuracy of the ocr\n",
    "\n",
    "for i in range(len(df)):\n",
    "    r = re.get(df['AWS link'][i])\n",
    "    print(r)\n",
    "    open('../' + name, 'wb').write(r.content)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9a00ff7b4804186bed77c4f59995e5e4a690b80622b30d4fb44d07178b0cbe5"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('human-rights-first-asylum-ds-a-bUMUEGIo': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}