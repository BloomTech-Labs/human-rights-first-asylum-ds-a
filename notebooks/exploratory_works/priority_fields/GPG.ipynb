{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "import string\n",
    "from typing import List, Tuple, Union, Callable, Dict, Iterator\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl (47.1 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from en-core-web-md==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (20.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: six in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.0.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('D:\\\\Lambda\\\\Labs\\\\human-rights-first-asylum-ds-a\\\\texts\\\\text cases') # Wherever files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "# phrases we are looking for in protected grounds\n",
    "# explore court documents if there are identifiers\n",
    "# when seaching for these patterns/phrases/tokens\n",
    "pattern = [\n",
    "    [{\"LOWER\": \"race\"}],\n",
    "    [{\"LOWER\": \"religion\"}],\n",
    "    [{\"LOWER\": \"nationality\"}],\n",
    "    [{\"LOWER\": \"social\"}, {\"LOWER\": \"group\"}],\n",
    "    [{\"LOWER\": \"political\"}, {\"LOWER\": \"opinion\"}]\n",
    "           ]\n",
    "matcher.add('protected_grounds',pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates searchable files to read in, and then test similar and get protected grounds\n",
    "counter = 0\n",
    "dict_name = {}\n",
    "for file in filenames:\n",
    "    counter += 1\n",
    "    f = open(f\"D:\\\\Lambda\\\\Labs\\\\human-rights-first-asylum-ds-a\\\\texts\\\\text cases\\\\{file}\", \"r\", encoding='utf-8')\n",
    "    dict_name[counter] = nlp(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Nationality,\n",
       " Nationality,\n",
       " nationality,\n",
       " nationality,\n",
       " nationality,\n",
       " nationality,\n",
       " nationality,\n",
       " nationality,\n",
       " nationality]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# already tokenized text\n",
    "doc_1 = dict_name[1]\n",
    "doc_2 = dict_name[2]\n",
    "# run matcher \n",
    "matches = matcher(doc_1, as_spans=True)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(target_phrases, file):\n",
    "    \n",
    "    \"\"\"GET RID OF PUNCT\"\"\"\n",
    "    # from string lib, we create an exclusion table\n",
    "    #table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    # then use that table to make a string without punct\n",
    "    #no_punct_string = target_phrases.translate(table)\n",
    "    # create matcher object and add the pattern we are looking for\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add('target_phrases', target_phrases)\n",
    "    matches = matcher(file, as_spans=True)\n",
    "    # in the functions where similiar is used,\n",
    "    # must present target_phrases in a list of dictionary using Spacy pattern syntax\n",
    "    # example\n",
    "    # pattern = [[{\"LOWER\": \"race\"}]]\n",
    "    # similar_pg = similar(target_phrases=pattern, file=self.doc)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protected_grounds(self):\n",
    "    \n",
    "    # list of protected grounds\n",
    "    # can expand this list and add different phrases to cover more ground\n",
    "    pattern = [\n",
    "    [{\"LOWER\": \"race\"}],\n",
    "    [{\"LOWER\": \"religion\"}],\n",
    "    [{\"LOWER\": \"nationality\"}], # currently, phrase is pulled but out of context\n",
    "    [{\"LOWER\": \"social\"}, {\"LOWER\": \"group\"}],\n",
    "    [{\"LOWER\": \"political\"}, {\"LOWER\": \"opinion\"}],\n",
    "    [{\"LOWER\": \"political\"}, {\"LOWER\": \"offense\"}],\n",
    "    [{\"LOWER\": \"protected\"}, {\"LOWER\": \"grounds\"}]\n",
    "           ]\n",
    "    pgs = []\n",
    "    similar_pg = similar(target_phrases=pattern, file=self.doc)\n",
    "    \n",
    "    # code edge cases where nationality isn't triggered by 'nationality act'\n",
    "    for token in self.doc:\n",
    "        if token.text.lower() == 'nationality':\n",
    "    \n",
    "    # get unique words that matched the phrases above \n",
    "    for phrase in similar_pg:\n",
    "        if phrase.text.lower() not in pgs:\n",
    "            pgs.append(phrase.text.lower())\n",
    "        return pgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nationality']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_protected_grounds(doc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
