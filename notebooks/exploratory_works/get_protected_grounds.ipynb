{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.6)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Tuple, Union, Callable, Dict, Iterator\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "import spacy \n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.tokens.span import Span\n",
    "from spacy.tokens.token import Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('./hrfCases') # Wherever files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    The\n",
      "1    respondent\n",
      "2    had\n",
      "3    a\n",
      "4    pending\n",
      "5    asylum\n",
      "6    application\n",
      "7    ,\n",
      "8    alleging\n",
      "9    a\n",
      "10    fear\n",
      "11    of\n",
      "12    harm\n",
      "13    on\n",
      "14    account\n",
      "15    of\n",
      "16    his\n",
      "17    race\n",
      "18    and\n",
      "19    membership\n",
      "20    in\n",
      "21    a\n",
      "22    particular\n",
      "23    social\n",
      "24    group\n",
      "25    (\n",
      "26    Exh\n",
      "27    .\n",
      "28    2\n",
      "29    )\n",
      "30    .\n",
      "31    The\n",
      "32    respondent\n",
      "33    showed\n",
      "34    due\n",
      "35    diligence\n",
      "36    in\n",
      "37    promptly\n",
      "38    seeking\n",
      "39    to\n",
      "40    redress\n",
      "41    the\n",
      "42    situation\n",
      "43    by\n",
      "44    filing\n",
      "45    his\n",
      "46    motion\n",
      "47    less\n",
      "48    than\n",
      "49    two\n",
      "50    months\n",
      "51    after\n",
      "52    the\n",
      "53    issuance\n",
      "54    of\n",
      "55    the\n",
      "56    in\n",
      "57    absentia\n",
      "58    order\n",
      "59    ,\n",
      "60    and\n",
      "61    DHS\n",
      "62    did\n",
      "63    not\n",
      "64    file\n",
      "65    an\n",
      "66    opposition\n",
      "67    to\n",
      "68    either\n",
      "69    the\n",
      "70    motion\n",
      "71    or\n",
      "72    the\n",
      "73    appeal\n"
     ]
    }
   ],
   "source": [
    "text = 'The respondent had a pending asylum application, alleging a fear of harm on account of his race and membership in a particular social group (Exh. 2). The respondent showed due diligence in promptly seeking to redress the situation by filing his motion less than two months after the issuance of the in absentia order, and DHS did not file an opposition to either the motion or the appeal'\n",
    "doc = nlp(text)\n",
    "i = 0\n",
    "for token in doc:\n",
    "    print(i, '  ', token.text)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23   False\n"
     ]
    }
   ],
   "source": [
    " pattern = [\n",
    "         [{\"LOWER\": \"social\"}, {\"LOWER\": \"group\"}],\n",
    "         ]\n",
    "matches = similar(target_phrases=pattern, file=doc)\n",
    "for match in matches:\n",
    "    print(match.start, ' ', in_parenthetical(match, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `similar()` and `similar_in_list()` are the current search methods for finding panel members within a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_parenthetical(match, doc):\n",
    "    open_parens = 0\n",
    "    for i in range(match.end, len(doc)):\n",
    "        if doc[i].text == '(':\n",
    "            open_parens += 1\n",
    "        elif doc[i].text == ')':\n",
    "            if open_parens > 0:\n",
    "                open_parens -= 1\n",
    "            else:\n",
    "                return True\n",
    "        elif doc[i] in {'.', '?', '!'}:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def similar_outcome(str1, str2):\n",
    "    \"\"\"\n",
    "    Returns True if the strings are off by a single character, and that \n",
    "    character is not a 'd' at the end. That 'd' at the end of a word is highly \n",
    "    indicative of whether something is actually an outcome.\n",
    "    \n",
    "    This is used in the get_outcome() method.\n",
    "    \"\"\"\n",
    "    if abs(len(str1) - len(str2)) > 1:\n",
    "        return False\n",
    "    min_len = min(len(str1), len(str2))\n",
    "    i = 0\n",
    "    while i < min_len and str1[i] == str2[i]:\n",
    "        i += 1\n",
    "\n",
    "    # We've reached the end of one string, the other is one character longer\n",
    "    if i == min_len:\n",
    "        # If that character is a 'd', return False, otherwise True\n",
    "        if ((len(str1) > len(str2) and str1[-1] == 'd') \n",
    "            or (len(str2) > len(str1) and str2[-1] == 'd')):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    # We're looking at a substitution that is 'd' at the end\n",
    "    if (i == len(str1) -1 and len(str1) == len(str2) \n",
    "        and (str1[-1] == 'd' or str2[-1] == 'd')):\n",
    "        return False\n",
    "\n",
    "    # We're looking at a substitution other than 'd' at the end\n",
    "    i2 = i + 1\n",
    "    while i2 < min_len and str1[i2] == str2[i2]:\n",
    "        i2 += 1\n",
    "    if i2 == len(str1) and i2 == len(str2):\n",
    "        return True\n",
    "\n",
    "    # We're in the middle, str1 has an extra character\n",
    "    if len(str1) == len(str2) + 1:\n",
    "        i2 = i\n",
    "        while i2 < min_len and str1[i2+1] == str2[i2]:\n",
    "            i2 += 1\n",
    "        if i2 + 1 == len(str1) and i2 == len(str2):\n",
    "            return True\n",
    "    \n",
    "    # We're in the middle, str2 has an extra character\n",
    "    if len(str1) + 1 == len(str2):\n",
    "        i2 = i\n",
    "        while i2 < min_len and str1[i2] == str2[i2+1]:\n",
    "            i2 += 1\n",
    "        if i2 == len(str1) and i2 + 1 == len(str2):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def similar(target_phrases, file):\n",
    "    ''' helper function to create spacy matcher\n",
    "    that searches for specified target_phrases,\n",
    "    simplifies get field names function, and improves\n",
    "    ability to change \n",
    "    '''\n",
    "    \"\"\"GET RID OF PUNCT\"\"\"\n",
    "    # from string lib, we create an exclusion table\n",
    "    #table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    # then use that table to make a string without punct\n",
    "    #no_punct_string = target_phrases.translate(table)\n",
    "    # create matcher object and add the pattern we are looking for\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add('target_phrases', target_phrases)\n",
    "    matches = matcher(file, as_spans=True)\n",
    "    # in the functions where similiar is used,\n",
    "    # must present target_phrases in a list of dictionary using Spacy pattern syntax\n",
    "    # example\n",
    "    # pattern = [[{\"LOWER\": \"race\"}]]\n",
    "    # similar_pg = similar(target_phrases=pattern, file=self.doc)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "class BIACase:\n",
    "    def __init__(self, text: str):\n",
    "        \"\"\"\n",
    "        • Input will be text from a BIA case pdf file, after the pdf has\n",
    "        been converted from PDF to text.\n",
    "        • Scraping works utilizing spaCy, tokenizing the text, and iterating\n",
    "        token by token searching for matching keywords.\n",
    "        \"\"\"\n",
    "        self.doc = nlp(text)\n",
    "        self.outcome = self.get_outcome()\n",
    "\n",
    "    def get_outcome_original(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        • Returns list of outcome terms from the case in a list.\n",
    "          These will appear after 'ORDER' at the end of the document.\n",
    "        \"\"\"\n",
    "\n",
    "        outcomes_return = []\n",
    "        ordered_outcome = {'ORDER', 'ORDERED'}\n",
    "        outcomes_list = ['denied', 'dismissed', 'granted', 'remanded', 'returned',\n",
    "                         'reversal', 'sustained', 'terminated', 'terninated', 'vacated']\n",
    "\n",
    "        # Interesting edge case in 349320269- typo on 'terminated' present in the pdf: fuzzywuzzy matches terminated\n",
    "        # to [(terninated, 90)]\n",
    "        ordered_i = -1\n",
    "        for token in self.doc:\n",
    "            if str(token) in ordered_outcome:\n",
    "                ordered_i = token.i\n",
    "                break\n",
    "                \n",
    "        # If we can't find where the orders start, assume there aren't any\n",
    "        if ordered_i == -1:\n",
    "            return []\n",
    "                \n",
    "        # If we can find where the orders start, check it for each type of outcome\n",
    "        for outcome in outcomes_list:\n",
    "            for i in range(ordered_i, min(ordered_i + 175, len(self.doc))):\n",
    "                if str(self.doc[i]) == outcome:\n",
    "                    outcomes_return.append(outcome)\n",
    "                    break\n",
    "                \n",
    "        return outcomes_return\n",
    "    \n",
    "    def get_outcome(self):\n",
    "        outcomes_return = []\n",
    "        ordered_outcome = {'ORDER', 'ORDERED'}\n",
    "        outcomes_list = ['denied', 'dismissed', 'granted', 'remanded',\n",
    "                         'returned', 'sustained', 'terminated',\n",
    "                         'vacated', 'affirmed']\n",
    "        two_before_exclusion = {'may', 'any', 'has'}\n",
    "        one_before_exclusion = {'it', 'has'}\n",
    "\n",
    "        # locate where in the document the orders start\n",
    "        order_start_i = -1\n",
    "        for token in self.doc:\n",
    "            if token.text in ordered_outcome:\n",
    "                order_start_i = token.i\n",
    "                break\n",
    "\n",
    "        # If we can't find where the orders start, assume they start at the beginning\n",
    "        if order_start_i == -1:\n",
    "            order_start_i = 0\n",
    "\n",
    "        # Locate where in the document the orders end\n",
    "        order_end_i = len(self.doc)\n",
    "        # Orders end when we see \"FOR THE BOARD\" or \"WARNING\"\n",
    "        # - this avoids finding keywords in footnotes or warnings\n",
    "        for i in range(order_start_i+1, min(order_end_i, len(self.doc) - 2)):\n",
    "            if (self.doc[i:i+3].text == \"FOR THE BOARD\" or\n",
    "                self.doc[i].text == \"WARNING\"):\n",
    "                order_end_i = i\n",
    "                break\n",
    "\n",
    "        # If we can find where the orders start, check the range for each type\n",
    "        # of outcome\n",
    "        for outcome in outcomes_list:\n",
    "            for i in range(order_start_i, order_end_i):\n",
    "                if (similar_outcome(self.doc[i].text, outcome) and\n",
    "                    self.doc[i-2].text not in two_before_exclusion and\n",
    "                    self.doc[i-1].text not in one_before_exclusion):\n",
    "                    outcomes_return.append(outcome)\n",
    "                    break\n",
    "\n",
    "        return outcomes_return\n",
    "    \n",
    "    def get_protected_grounds_old(self):\n",
    "        religions = ['christianity','christian','islam','atheist','hinduism','buddihism','jewish','judaism']\n",
    "        \n",
    "        # list of protected grounds\n",
    "        # can expand this list and add different phrases to cover more ground\n",
    "        pattern = [\n",
    "        [{\"LOWER\": \"race\"}], \n",
    "        [{\"LOWER\": \"religion\"}], # expand to check for list of religions\n",
    "        [{\"LOWER\": \"nationality\"}], # currently, phrase is pulled but out of context\n",
    "        [{\"LOWER\": \"social\"}, {\"LOWER\": \"group\"}], \n",
    "        [{\"LOWER\": \"political\"}, {\"LOWER\": \"opinion\"}],\n",
    "        [{\"LOWER\": \"political\"}, {\"LOWER\": \"offense\"}],\n",
    "        #[{\"LOWER\": \"protected\"}, {\"LOWER\": \"grounds\"}],\n",
    "        [{\"LOWER\": \"political\"}],\n",
    "        ]\n",
    "        # included major religions to expand search for religion\n",
    "        for religion in religions:\n",
    "            pattern.append([{'LOWER': religion}])\n",
    "\n",
    "        politicals = ['political opinion', 'political offense']\n",
    "        \n",
    "        exclusions = ['real id', 'grounds specified', 'no claim']\n",
    "        # potential grounds is a list of Span objects that have added functionality\n",
    "        # in order to weed out bad tokens\n",
    "        potential_grounds = similar(target_phrases=pattern, file=self.doc)\n",
    "        # explore idea to implement a deque for more efficiency \n",
    "        confirmed_matches = []\n",
    "        # check for exclusion phrases, remove match if found\n",
    "        for match in potential_grounds:\n",
    "        # remove 'nationality act' from potential_grounds\n",
    "            if match.text.lower() == 'nationality':\n",
    "                if 'act' in match.sent.text.lower():\n",
    "                    potential_grounds.remove(match)\n",
    "                else:\n",
    "                    if 'nationality' not in confirmed_matches:\n",
    "                        confirmed_matches.append('nationality')\n",
    "        # check for specified religion, replace with 'religion'\n",
    "            elif match.text.lower() in religions:\n",
    "                #print(match)\n",
    "                potential_grounds.remove(match)\n",
    "                if 'religion' not in confirmed_matches:\n",
    "                    confirmed_matches.append('religion')\n",
    "            elif match.text.lower() in politicals:\n",
    "                potential_grounds.remove(match)\n",
    "                if 'political' not in confirmed_matches:\n",
    "                    confirmed_matches.append('political')\n",
    "            else:\n",
    "                confirmed_matches.append(match.text.lower())\n",
    "        \n",
    "        #result = [str(i).lower() for i in potential_grounds] + confirmed_matches\n",
    "        if confirmed_matches:\n",
    "            return list(set(confirmed_matches))\n",
    "        #if result:\n",
    "        #    return set(result), confirmed_matches\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    def get_protected_grounds(self):\n",
    "        religions = ['christianity','christian','islam','atheist','hinduism','buddihism','jewish','judaism']\n",
    "        \n",
    "        # list of protected grounds\n",
    "        # can expand this list and add different phrases to cover more ground\n",
    "        pattern = [\n",
    "        [{\"LOWER\": \"race\"}], \n",
    "        [{\"LOWER\": \"religion\"}], # expand to check for list of religions\n",
    "        [{\"LOWER\": \"nationality\"}], # currently, phrase is pulled but out of context\n",
    "        [{\"LOWER\": \"social\"}, {\"LOWER\": \"group\"}], \n",
    "        [{\"LOWER\": \"political\"}, {\"LOWER\": \"opinion\"}],\n",
    "        [{\"LOWER\": \"political\"}, {\"LOWER\": \"offense\"}],\n",
    "        #[{\"LOWER\": \"protected\"}, {\"LOWER\": \"grounds\"}],\n",
    "        [{\"LOWER\": \"political\"}],\n",
    "        ]\n",
    "        # included major religions to expand search for religion\n",
    "        for religion in religions:\n",
    "            pattern.append([{'LOWER': religion}])\n",
    "\n",
    "        politicals = ['political opinion', 'political offense']\n",
    "        \n",
    "        exclusions = ['real id', 'grounds specified', 'no claim']\n",
    "        # potential grounds is a list of Span objects that have added functionality\n",
    "        # in order to weed out bad tokens\n",
    "        potential_grounds = similar(target_phrases=pattern, file=self.doc)\n",
    "        # explore idea to implement a deque for more efficiency \n",
    "        confirmed_matches = []\n",
    "        # check for exclusion phrases, remove match if found\n",
    "        for match in potential_grounds:\n",
    "        # remove 'nationality act' from potential_grounds\n",
    "            if match.text.lower() == 'nationality':\n",
    "                if 'act' in match.sent.text.lower():\n",
    "                    potential_grounds.remove(match)\n",
    "                else:\n",
    "                    if 'nationality' not in confirmed_matches:\n",
    "                        confirmed_matches.append('nationality')\n",
    "        # check for specified religion, replace with 'religion'\n",
    "            elif match.text.lower() in religions:\n",
    "                #print(match)\n",
    "                potential_grounds.remove(match)\n",
    "                if 'religion' not in confirmed_matches:\n",
    "                    confirmed_matches.append('religion')\n",
    "            elif match.text.lower() in politicals:\n",
    "                potential_grounds.remove(match)\n",
    "                if 'political' not in confirmed_matches:\n",
    "                    confirmed_matches.append('political')\n",
    "            elif in_parenthetical(match, self.doc):\n",
    "                potential_grounds.remove(match)\n",
    "            else:\n",
    "                confirmed_matches.append(match.text.lower())\n",
    "        \n",
    "        #result = [str(i).lower() for i in potential_grounds] + confirmed_matches\n",
    "        if confirmed_matches:\n",
    "            return list(set(confirmed_matches))\n",
    "        #if result:\n",
    "        #    return set(result), confirmed_matches\n",
    "        else:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:  165227167-K-O-A-BIA-Aug-27-2013-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n",
      "file:  205871959-M-G-O-AXXX-XXX-611-BIA-Feb-4-2014-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  271354416-D-M-R-BIA-June-9-2015-output-1-to-6.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  311736830-H-R-M-AXXX-XXX-381-BIA-March-14-2016-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  334139459-S-V-C-AXXX-XXX-431-BIA-Nov-1-2016-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['religion', 'political', 'social group']\n",
      "file:  337540716-Clebson-Sousa-Carneiro-A078-254-701-BIA-Jan-6-2017-output-1-to-10.txt\n",
      "new outcome:  ['social group']\n",
      "old outcome:  ['nationality', 'political', 'race', 'social group']\n",
      "file:  371997958-Rocio-Alida-Valencia-Barragan-A209-138-515-BIA-Feb-5-2018-output-1-to-7.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  377420389-A-L-D-G-AXXX-XXX-287-BIA-March-14-2018-output-1-to-4.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['religion', 'political', 'race', 'social group']\n",
      "file:  382793281-J-M-O-M-AXXX-XXX-580-BIA-May-16-2018-output-1-to-6.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  389525713-Y-M-AXXX-XX-937-BIA-Aug-14-2018-output-1-to-4.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n",
      "file:  398004575-X-G-C-D-AXXX-XXX-474-BIA-Dec-11-2018-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  406491549-K-A-A-P-AXXX-XXX-625-BIA-March-7-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  406499054-M-H-A-AXXX-XXX-784-BIA-March-15-2019-output-1-to-4.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  406502213-Nevanly-Cisse-A077-943-726-BIA-April-1-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  411263766-J-W-A-L-AXXX-XXX-848-BIA-April-26-2019-output-1-to-6.txt\n",
      "new outcome:  ['nationality']\n",
      "old outcome:  ['religion', 'race', 'political']\n",
      "file:  414382702-M-I-A-R-AXXX-XXX-985-BIA-May-24-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['religion', 'nationality', 'political', 'social group']\n",
      "file:  414384547-O-A-M-A-AXXX-XXX-347-BIA-June-4-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n",
      "file:  419389899-G-A-AXXX-XXX-612-BIA-June-21-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['religion']\n",
      "file:  419391625-J-R-F-F-AXXX-XXX-634-BIA-July-9-2019-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  427093204-S-I-AXXX-XXX-729-BIA-Aug-29-2019-output-1-to-6.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  431711050-C-N-A-AXXX-XXX-484-BIA-Sept-12-2019-output-1-to-4.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['religion', 'political', 'race', 'social group']\n",
      "file:  431713163-S-J-G-AXXX-XXX-005-BIA-Sept-23-2019-output-1-to-5.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  437041962-J-J-AXXX-XXX-686-BIA-Oct-23-2019-output-1-to-6.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  443776154-C-T-AXXX-XXX-676-BIA-Dec-18-2019-output-1-to-4.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n",
      "file:  443776197-L-F-A-AXXX-XXX-919-BIA-Dec-18-2019-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['race', 'social group']\n",
      "file:  447696312-J-V-S-E-AXXX-XXX-159-BIA-Jan-10-2020-output-1-to-5.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  447701547-M-S-D-AXXX-XXX-451-BIA-Jan-28-2020-output-1-to-3.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n",
      "file:  457374430-A-E-M-P-AXXX-XXX-795-BIA-March-16-2020-output-1-to-3.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  462824675-D-E-D-L-AXXX-XXX-662-BIA-April-10-2020-output-1-to-4.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  470812759-K-A-B-R-AXXX-XXX-670-BIA-June-22-2020-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['social group']\n",
      "file:  470814353-K-I-AXXX-XXX-247-BIA-July-7-2020-output-1-to-4.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  473846393-K-I-AXXX-XXX-247-BIA-July-7-2020-output-1-to-4.txt\n",
      "new outcome:  ['political']\n",
      "old outcome:  ['political', 'social group']\n",
      "file:  473851235-K-I-AXXX-XXX-553-BIA-Aug-5-2020-output-1-to-4.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['religion']\n",
      "file:  477308560-Q-C-AXX-XXX-001-BIA-Sept-1-2020-output-1-to-4.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['religion']\n",
      "file:  477308672-H-D-L-AXXX-XXX-563-BIA-Sept-3-2020-output-1-to-5.txt\n",
      "new outcome:  []\n",
      "old outcome:  ['political']\n"
     ]
    }
   ],
   "source": [
    "new_pg_dict = {}\n",
    "old_pg_dict = {}\n",
    "\n",
    "for file in filenames:\n",
    "    f = open(f\"./hrfCases/{file}\", \"r\", encoding='utf-8')\n",
    "    case = BIACase(f.read())\n",
    "    old_pg = case.get_protected_grounds_old()\n",
    "    old_pg_dict[file] = old_pg\n",
    "    new_pg = case.get_protected_grounds()\n",
    "    new_pg_dict[file] = new_pg\n",
    "    if old_pg != new_pg:\n",
    "        print('file: ', file)\n",
    "        print('new outcome: ', new_pg)\n",
    "        print('old outcome: ', old_pg)\n",
    "    f.close()\n",
    "\n",
    "new_pg_df = pd.DataFrame(new_pg_dict.items(), columns=['UUID', 'new_pg'])\n",
    "old_pg_df = pd.DataFrame(old_pg_dict.items(), columns=['UUID', 'old_pg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve correct manually extracted data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>protected grounds</th>\n",
       "      <th>new_pg</th>\n",
       "      <th>old_pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140194281-Ali-Fares-A047-654-200-BIA-Apr-30-2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nationality]</td>\n",
       "      <td>[nationality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165227167-K-O-A-BIA-Aug-27-2013</td>\n",
       "      <td>Social, Political</td>\n",
       "      <td>[]</td>\n",
       "      <td>[political]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[race]</td>\n",
       "      <td>[race]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175361890-Jose-Zacaria-Quinteros-A088-239-850-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202216334-Francisco-Hernandez-Pina-A073-976-63...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                UUID  protected grounds  \\\n",
       "0   140194281-Ali-Fares-A047-654-200-BIA-Apr-30-2013                NaN   \n",
       "1                    165227167-K-O-A-BIA-Aug-27-2013  Social, Political   \n",
       "2  171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...                NaN   \n",
       "3  175361890-Jose-Zacaria-Quinteros-A088-239-850-...                NaN   \n",
       "4  202216334-Francisco-Hernandez-Pina-A073-976-63...                NaN   \n",
       "\n",
       "          new_pg         old_pg  \n",
       "0  [nationality]  [nationality]  \n",
       "1             []    [political]  \n",
       "2         [race]         [race]  \n",
       "3             []             []  \n",
       "4             []             []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv('manually_scrapped.csv')\n",
    "df_csv = df_csv[['UUID', 'protected grounds']]\n",
    "\n",
    "#remove .pdf\n",
    "df_csv['UUID'] = df_csv['UUID'].str[0:-4] \n",
    "\n",
    "#remove different ending of .txt file names\n",
    "new_pg_df['UUID'] = new_pg_df['UUID'].apply(lambda x : x[0:x.find('output-1-to-') - 1])\n",
    "old_pg_df['UUID'] = old_pg_df['UUID'].apply(lambda x : x[0:x.find('output-1-to-') - 1])\n",
    "\n",
    "combined_df = df_csv.merge(new_pg_df, on='UUID', how='outer').merge(old_pg_df, on='UUID', how='outer')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compare_pgs(row, version, ground=None):\n",
    "    if ground == None:\n",
    "        if row['protected grounds'] != row['protected grounds']:\n",
    "            return row[version+'_pg'] == []\n",
    "\n",
    "        list1 = row['protected grounds'].lower().split(', ')\n",
    "        list2 = row[version+'_pg']\n",
    "        list1.sort()\n",
    "        list2.sort()\n",
    "        if len(list1) != len(list2):\n",
    "            return False\n",
    "        for i in range(len(list1)):\n",
    "            if list1[i] != list2[i]:\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        list2 = row[version+'_pg']\n",
    "        if row['protected grounds'] != row['protected grounds']:\n",
    "            return ground not in list2\n",
    "        list1 = row['protected grounds'].lower().split(', ')\n",
    "        return (ground in list1) == (ground in list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old accuracy:  97.6470588235294 %\n",
      "new accuracy:  98.23529411764706 %\n",
      "improvement:    0.5882352941176521 %\n"
     ]
    }
   ],
   "source": [
    "ground = 'race'\n",
    "\n",
    "combined_df['old_accurate'] = combined_df.apply(compare_pgs, args=['old', ground], axis=1)\n",
    "combined_df['new_accurate'] = combined_df.apply(compare_pgs, args=['new', ground], axis=1)\n",
    "\n",
    "old_accuracy = combined_df['old_accurate'].sum()/len(combined_df)*100\n",
    "new_accuracy = combined_df['new_accurate'].sum()/len(combined_df)*100\n",
    "print('old accuracy: ', old_accuracy, \"%\")\n",
    "print('new accuracy: ', new_accuracy, \"%\")\n",
    "print(\"improvement:   \", new_accuracy - old_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>protected grounds</th>\n",
       "      <th>new_pg</th>\n",
       "      <th>old_pg</th>\n",
       "      <th>old_accurate</th>\n",
       "      <th>new_accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[race]</td>\n",
       "      <td>[race]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>337540716-Clebson-Sousa-Carneiro-A078-254-701-...</td>\n",
       "      <td>race, nationality, political</td>\n",
       "      <td>[social group]</td>\n",
       "      <td>[nationality, political, race, social group]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>443776197-L-F-A-AXXX-XXX-919-BIA-Dec-18-2019</td>\n",
       "      <td>race, social</td>\n",
       "      <td>[]</td>\n",
       "      <td>[race, social group]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  UUID  \\\n",
       "2    171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...   \n",
       "16   337540716-Clebson-Sousa-Carneiro-A078-254-701-...   \n",
       "114       443776197-L-F-A-AXXX-XXX-919-BIA-Dec-18-2019   \n",
       "\n",
       "                protected grounds          new_pg  \\\n",
       "2                             NaN          [race]   \n",
       "16   race, nationality, political  [social group]   \n",
       "114                  race, social              []   \n",
       "\n",
       "                                           old_pg  old_accurate  new_accurate  \n",
       "2                                          [race]         False         False  \n",
       "16   [nationality, political, race, social group]          True         False  \n",
       "114                          [race, social group]          True         False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_df = combined_df[combined_df['new_accurate'] == False]\n",
    "print(len(diff_df))\n",
    "diff_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>protected grounds</th>\n",
       "      <th>new_pg</th>\n",
       "      <th>old_pg</th>\n",
       "      <th>old_accurate</th>\n",
       "      <th>new_accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>337540716-Clebson-Sousa-Carneiro-A078-254-701-...</td>\n",
       "      <td>race, nationality, political</td>\n",
       "      <td>[social group]</td>\n",
       "      <td>[nationality, political, race, social group]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>377420389-A-L-D-G-AXXX-XXX-287-BIA-March-14-2018</td>\n",
       "      <td>Social Group</td>\n",
       "      <td>[political]</td>\n",
       "      <td>[religion, political, race, social group]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>411263766-J-W-A-L-AXXX-XXX-848-BIA-April-26-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nationality]</td>\n",
       "      <td>[religion, race, political]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>431711050-C-N-A-AXXX-XXX-484-BIA-Sept-12-2019</td>\n",
       "      <td>political; social</td>\n",
       "      <td>[political]</td>\n",
       "      <td>[religion, political, race, social group]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>443776197-L-F-A-AXXX-XXX-919-BIA-Dec-18-2019</td>\n",
       "      <td>race, social</td>\n",
       "      <td>[]</td>\n",
       "      <td>[race, social group]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  UUID  \\\n",
       "16   337540716-Clebson-Sousa-Carneiro-A078-254-701-...   \n",
       "30    377420389-A-L-D-G-AXXX-XXX-287-BIA-March-14-2018   \n",
       "73    411263766-J-W-A-L-AXXX-XXX-848-BIA-April-26-2019   \n",
       "97       431711050-C-N-A-AXXX-XXX-484-BIA-Sept-12-2019   \n",
       "114       443776197-L-F-A-AXXX-XXX-919-BIA-Dec-18-2019   \n",
       "\n",
       "                protected grounds          new_pg  \\\n",
       "16   race, nationality, political  [social group]   \n",
       "30                   Social Group     [political]   \n",
       "73                            NaN   [nationality]   \n",
       "97              political; social     [political]   \n",
       "114                  race, social              []   \n",
       "\n",
       "                                           old_pg  old_accurate  new_accurate  \n",
       "16   [nationality, political, race, social group]          True         False  \n",
       "30      [religion, political, race, social group]         False          True  \n",
       "73                    [religion, race, political]         False          True  \n",
       "97      [religion, political, race, social group]         False          True  \n",
       "114                          [race, social group]          True         False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes_df = combined_df[combined_df['new_accurate'] != combined_df['old_accurate']]\n",
    "print(len(changes_df))\n",
    "changes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
