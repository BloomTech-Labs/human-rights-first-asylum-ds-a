{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.6.20)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Tuple, Union, Callable, Dict, Iterator\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "import spacy \n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.tokens.span import Span\n",
    "from spacy.tokens.token import Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('./hrfCases') # Wherever files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a: str, return_b: str, min_score: float) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    • Returns 2nd string if similarity score is above supplied\n",
    "    minimum score. Else, returns None.\n",
    "    \"\"\"\n",
    "    if SequenceMatcher(None, a, return_b).ratio() >= min_score:\n",
    "        return return_b\n",
    "\n",
    "\n",
    "def similar_in_list(lst: Union[List[str], Iterator[str]]) -> Callable:\n",
    "    \"\"\"\n",
    "    • Uses a closure on supplied list to return a function that iterates over\n",
    "    the list in order to search for the first similar term. It's used widely\n",
    "    in the scraper.\n",
    "    \"\"\"\n",
    "\n",
    "    def impl(item: str, min_score: float) -> Union[str, None]:\n",
    "        for s in lst:\n",
    "            s = similar(item, s, min_score)\n",
    "            if s:\n",
    "                return s\n",
    "\n",
    "    return impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIACase:\n",
    "    def __init__(self, text: str):\n",
    "        \"\"\"\n",
    "        • Input will be text from a BIA case pdf file, after the pdf has\n",
    "        been converted from PDF to text.\n",
    "        • Scraping works utilizing spaCy, tokenizing the text, and iterating\n",
    "        token by token searching for matching keywords.\n",
    "        \"\"\"\n",
    "        self.doc: Doc = nlp(text)\n",
    "        self.ents: Tuple[Span] = self.doc.ents\n",
    "        self.state = None\n",
    "        self.city = None\n",
    "        \n",
    "    def check_for_one_year_original(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks whether or not the asylum-seeker argued to be exempt from the\n",
    "        one-year guideline.  Specifically, it checks to see if the document\n",
    "        contains either \"changed circumstance\" or \"extraordinary circumstance\".\n",
    "        If it does, and one of the five terms (\"year\", \"delay\", \"time\",\n",
    "        \"period\", \"deadline\") is within 10 lemmas, then the function\n",
    "        returns True.  Otherwise, it returns False.\n",
    "        If one of the four context words are w/in 100 characters of the\n",
    "        phrase, we conclude that it is related to the one-year rule\n",
    "        \"\"\"\n",
    "        terms = ('year', 'delay', 'time', 'period', 'deadline')\n",
    "        lemma_list = [token.lemma_.lower() for token in self.doc]\n",
    "\n",
    "        for idx in range(0, len(lemma_list)):\n",
    "            if lemma_list[idx] == 'change' and \\\n",
    "                    lemma_list[idx + 1] == 'circumstance':\n",
    "                idx_start = lemma_list.index('change')\n",
    "                idx_end = idx_start + 1\n",
    "                search_list = [\n",
    "                    lemma for lemma in lemma_list[idx_start - 10: idx_end + 10]\n",
    "                ]\n",
    "                if any(term in search_list for term in terms):\n",
    "                    return True\n",
    "\n",
    "        for idx in range(0, len(lemma_list)):\n",
    "            if lemma_list[idx] == 'extraordinary' and \\\n",
    "                    lemma_list[idx + 1] == 'circumstance':\n",
    "                idx_start = lemma_list.index('extraordinary')\n",
    "                idx_end = idx_start + 1\n",
    "                search_list = [\n",
    "                    lemma for lemma in lemma_list[idx_start - 10: idx_end + 10]\n",
    "                ]\n",
    "                if any(term in search_list for term in terms):\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def check_for_one_year(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks whether or not the asylum-seeker argued to be exempt from the\n",
    "        one-year guideline.\n",
    "        \"\"\"\n",
    "        # If any of these terms appear in the document, return True\n",
    "        terms_len_3 = {'within one year', 'within 1 year'}\n",
    "        terms_len_4 = {'within 1 - year', 'within one - year'}\n",
    "        \n",
    "        # If a pimary term and a secondary term appear in the same\n",
    "        # sentence, return True\n",
    "        primary_terms_len_2 = {'change circumstance', \n",
    "                               'extraordinary circumstance', \n",
    "                               'untimely application'}\n",
    "        primary_terms_len_3 = {'change \\\" circumstance', \n",
    "                               'extraordinary \\\" circumstance'}\n",
    "        secondary_terms = {'year', 'delay', 'time', 'period', 'deadline'}\n",
    "\n",
    "        for i in range(len(self.doc)):\n",
    "            if self.doc[i:i+2].lemma_ in primary_terms_len_2 \\\n",
    "                or self.doc[i:i+3].lemma_ in primary_terms_len_3:\n",
    "                for token in self.doc[i].sent:\n",
    "                    if token.lemma_ in secondary_terms:\n",
    "                        return True\n",
    "                    \n",
    "            if self.doc[i:i+3].lemma_ in terms_len_3 \\\n",
    "                or self.doc[i:i+4].lemma_ in terms_len_4:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def check_for_one_year_new(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks whether or not the asylum-seeker argued to be exempt from the\n",
    "        one-year guideline.\n",
    "        \n",
    "        Returns true if the phrase \"within one-year\" appears in the document.\n",
    "        Also returns true if a time-based word appears in the same sentence\n",
    "        with \"extraordinary circumstances\" or \"changed circumstances\" or\n",
    "        \"untimely application\". Otherwise, returns False.\n",
    "        \n",
    "        \"\"\"\n",
    "        year_pattern = [\n",
    "            [{'LOWER':'within'}, {'LOWER': {'IN':['1', 'one']}}, \n",
    "             {'LOWER': '-', 'OP': '?'}, {'LOWER': 'year'}]\n",
    "        ]\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add('year pattern', year_pattern)\n",
    "        matches = matcher(self.doc, as_spans=True)\n",
    "        if matches:\n",
    "            return True\n",
    "        matcher.remove('year pattern')\n",
    "        \n",
    "        secondary_terms = {'year', 'delay', 'time', 'period', 'deadline'}\n",
    "        circumstance_pattern = [\n",
    "            [{'LEMMA': {'IN':['change', 'extraordinary']}}, \n",
    "             {'LOWER': {'IN':['\"', '”']}, 'OP': '?'}, {'LEMMA': 'circumstance'}]\n",
    "        ]\n",
    "        application_pattern = [\n",
    "            [{'LOWER':'untimely'}, {'LOWER':'application'}]\n",
    "        ]\n",
    "        matcher.add('circumstance pattern', circumstance_pattern)\n",
    "        matcher.add('application pattern', application_pattern)\n",
    "        matches = matcher(self.doc, as_spans=True)\n",
    "        for match in matches:\n",
    "            for token in match.sent:\n",
    "                if token.lemma_ in secondary_terms:\n",
    "                    return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "8\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "8\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "new_outcome_dict = {}\n",
    "old_outcome_dict = {}\n",
    "\n",
    "for file in filenames:\n",
    "    f = open(f\"./hrfCases/{file}\", \"r\", encoding='utf-8')\n",
    "    case = BIACase(f.read())\n",
    "    old_outcome = case.check_for_one_year()\n",
    "    old_outcome_dict[file] = old_outcome\n",
    "    new_outcome = case.check_for_one_year_new()\n",
    "    new_outcome_dict[file] = new_outcome\n",
    "    if old_outcome != new_outcome:\n",
    "        print('case: ', file)\n",
    "        print('new outcome: ', new_outcome)\n",
    "        print('old outcome: ', old_outcome)\n",
    "    f.close()\n",
    "\n",
    "new_outcome_df = pd.DataFrame(new_outcome_dict.items(), columns=['UUID', 'new_check_for_one_year'])\n",
    "old_outcome_df = pd.DataFrame(old_outcome_dict.items(), columns=['UUID', 'old_check_for_one_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.68866777420044\n",
      "49.58596181869507\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for file in filenames:\n",
    "    f = open(f\"./hrfCases/{file}\", \"r\", encoding='utf-8')\n",
    "    case = BIACase(f.read())\n",
    "    case.check_for_one_year_new()\n",
    "    f.close()\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for file in filenames:\n",
    "    f = open(f\"./hrfCases/{file}\", \"r\", encoding='utf-8')\n",
    "    case = BIACase(f.read())\n",
    "    case.check_for_one_year()\n",
    "    f.close()\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve correct manually extracted data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>new_check_for_one_year</th>\n",
       "      <th>old_check_for_one_year</th>\n",
       "      <th>check_for_one_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140194281-Ali-Fares-A047-654-200-BIA-Apr-30-2013</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165227167-K-O-A-BIA-Aug-27-2013</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175361890-Jose-Zacaria-Quinteros-A088-239-850-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202216334-Francisco-Hernandez-Pina-A073-976-63...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                UUID  new_check_for_one_year  \\\n",
       "0   140194281-Ali-Fares-A047-654-200-BIA-Apr-30-2013                   False   \n",
       "1                    165227167-K-O-A-BIA-Aug-27-2013                    True   \n",
       "2  171952033-Luis-Narciso-Sedeno-Trujillo-A088-19...                   False   \n",
       "3  175361890-Jose-Zacaria-Quinteros-A088-239-850-...                   False   \n",
       "4  202216334-Francisco-Hernandez-Pina-A073-976-63...                   False   \n",
       "\n",
       "   old_check_for_one_year  check_for_one_year  \n",
       "0                   False               False  \n",
       "1                    True                True  \n",
       "2                   False               False  \n",
       "3                   False               False  \n",
       "4                   False               False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_csv = pd.read_csv('manually_scrapped.csv')\n",
    "df_csv = df_csv[['UUID', 'check for one year']]\n",
    "\n",
    "#remove .pdf\n",
    "df_csv['UUID'] = df_csv['UUID'].str[0:-4] \n",
    "\n",
    "#remove different ending of .txt file names\n",
    "new_outcome_df['UUID'] = new_outcome_df['UUID'].apply(lambda x : x[0:x.find('output-1-to-') - 1])\n",
    "old_outcome_df['UUID'] = old_outcome_df['UUID'].apply(lambda x : x[0:x.find('output-1-to-') - 1])\n",
    "\n",
    "combined_df = df_csv.merge(new_outcome_df, on='UUID', how='outer').merge(old_outcome_df, on='UUID', how='outer')\n",
    "combined_df = combined_df[(combined_df['check for one year'] == '0') | (combined_df['check for one year'] == '1')]\n",
    "combined_df['check_for_one_year'] = np.where(combined_df['check for one year']=='1', True, False)\n",
    "combined_df = combined_df.drop('check for one year', axis=1)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old accuracy:  100.0 %\n",
      "new accuracy:  100.0 %\n",
      "improvement:    0.0 %\n"
     ]
    }
   ],
   "source": [
    "combined_df['old_accurate'] = (combined_df['old_check_for_one_year'] == combined_df['check_for_one_year'])\n",
    "combined_df['new_accurate'] = (combined_df['new_check_for_one_year'] == combined_df['check_for_one_year'])\n",
    "\n",
    "old_accuracy = combined_df['old_accurate'].sum()/len(combined_df)*100\n",
    "new_accuracy = combined_df['new_accurate'].sum()/len(combined_df)*100\n",
    "print('old accuracy: ', old_accuracy, \"%\")\n",
    "print('new accuracy: ', new_accuracy, \"%\")\n",
    "print(\"improvement:   \", new_accuracy - old_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>new_check_for_one_year</th>\n",
       "      <th>old_check_for_one_year</th>\n",
       "      <th>check_for_one_year</th>\n",
       "      <th>old_accurate</th>\n",
       "      <th>new_accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UUID, new_check_for_one_year, old_check_for_one_year, check_for_one_year, old_accurate, new_accurate]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_df = combined_df[combined_df['new_accurate'] == False]\n",
    "print(len(diff_df))\n",
    "diff_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>new_check_for_one_year</th>\n",
       "      <th>old_check_for_one_year</th>\n",
       "      <th>check_for_one_year</th>\n",
       "      <th>old_accurate</th>\n",
       "      <th>new_accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UUID, new_check_for_one_year, old_check_for_one_year, check_for_one_year, old_accurate, new_accurate]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes_df = combined_df[combined_df['new_accurate'] != combined_df['old_accurate']]\n",
    "print(len(changes_df))\n",
    "changes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
